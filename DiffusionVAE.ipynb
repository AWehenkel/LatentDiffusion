{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2372aioh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 65647<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.19MB of 2.19MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/awehenkel/Documents/Ecole/2020-2021/Research/LatentDiffusion/wandb/run-20210209_140748-2372aioh/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/awehenkel/Documents/Ecole/2020-2021/Research/LatentDiffusion/wandb/run-20210209_140748-2372aioh/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>19.00525</td></tr><tr><td>_step</td><td>44</td></tr><tr><td>_runtime</td><td>1324</td></tr><tr><td>_timestamp</td><td>1612877396</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>█▅▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 46 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dandy-field-159</strong>: <a href=\"https://wandb.ai/awehenkel/latent_diffusion/runs/2372aioh\" target=\"_blank\">https://wandb.ai/awehenkel/latent_diffusion/runs/2372aioh</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2372aioh). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.17<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">proud-bird-185</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/awehenkel/latent_diffusion\" target=\"_blank\">https://wandb.ai/awehenkel/latent_diffusion</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/awehenkel/latent_diffusion/runs/jx18s5uj\" target=\"_blank\">https://wandb.ai/awehenkel/latent_diffusion/runs/jx18s5uj</a><br/>\n",
       "                Run data is saved locally in <code>/Users/awehenkel/Documents/Ecole/2020-2021/Research/LatentDiffusion/wandb/run-20210209_143029-jx18s5uj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from Models import TemporalDecoder, TemporalEncoder, DataDiffuser, TransitionNet, SimpleImageDecoder, SimpleImageEncoder, PositionalEncoder, StupidPositionalEncoder\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_noise(x):\n",
    "    \"\"\"\n",
    "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
    "    \"\"\"\n",
    "    noise = x.new().resize_as_(x).uniform_()\n",
    "    x = x * 255 + noise\n",
    "    x = x / 256\n",
    "    return x\n",
    "\n",
    "def getMNISTDataLoader(bs):\n",
    "    # MNIST Dataset\n",
    "    train_dataset = datasets.MNIST(root='./mnist_data/', train=True, download=True, transform=transforms.Compose([\n",
    "                                      transforms.Resize((32, 32)),\n",
    "                                      #transforms.ToTensor(),\n",
    "                                      #add_noise,\n",
    "                                      ToTensor(),\n",
    "        AddUniformNoise()\n",
    "                                  ]))\n",
    "    test_dataset = datasets.MNIST(root='./mnist_data/', train=False, download=True,\n",
    "                                  transform=transforms.Compose([\n",
    "                                      transforms.Resize((32, 32)),\n",
    "                                      #transforms.ToTensor(),\n",
    "                                      #add_noise,\n",
    "                                      ToTensor(),\n",
    "                                      AddUniformNoise()\n",
    "                                  ]))\n",
    "\n",
    "    # Data Loader (Input Pipeline)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def getCIFAR10DataLoader(bs):\n",
    "    # MNIST Dataset\n",
    "    train_dataset = datasets.CIFAR10(root='./cifar10_data/', train=True, download=True, transform=transforms.Compose([\n",
    "                                      transforms.Resize(32),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      add_noise,\n",
    "                                      # transforms.ToTensor()\n",
    "                                  ]))\n",
    "    test_dataset = datasets.CIFAR10(root='./cifar10_data/', train=False, download=True,\n",
    "                                  transform=transforms.Compose([\n",
    "                                      transforms.Resize(32),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      add_noise,\n",
    "                                      # transforms.ToTensor()\n",
    "                                  ]))\n",
    "\n",
    "    # Data Loader (Input Pipeline)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def logit(x, alpha=1E-6):\n",
    "    y = alpha + (1.-2*alpha)*x\n",
    "    return np.log(y) - np.log(1. - y)\n",
    "\n",
    "\n",
    "def logit_back(x, alpha=1E-6):\n",
    "    y = torch.sigmoid(x)\n",
    "    return (y - alpha)/(1.-2*alpha)\n",
    "\n",
    "\n",
    "class AddUniformNoise(object):\n",
    "    def __init__(self, alpha=1E-6):\n",
    "        self.alpha = alpha\n",
    "    def __call__(self,samples):\n",
    "        samples = np.array(samples,dtype = np.float32)\n",
    "        samples += np.random.uniform(size = samples.shape)\n",
    "        samples = logit(samples/256., self.alpha)\n",
    "        return samples\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self,samples):\n",
    "        samples = torch.from_numpy(np.array(samples,dtype = np.float32)).float()\n",
    "        return samples\n",
    "\n",
    "\n",
    "class CNNDiffusionModel(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CNNDiffusionModel, self).__init__()\n",
    "        self.T_MAX = kwargs['T_MAX']\n",
    "        self.latent_s = kwargs['latent_s']\n",
    "        self.t_emb_s = kwargs['t_emb_s']\n",
    "        self.CNN = kwargs['CNN']\n",
    "        self.register_buffer(\"beta_min\", torch.tensor(kwargs['beta_min']))\n",
    "        self.register_buffer(\"beta_max\", torch.tensor(kwargs['beta_max']))\n",
    "        self.device = 'cpu'\n",
    "        self.img_size = [1, 32, 32]\n",
    "        self.pos_enc = PositionalEncoder(self.t_emb_s // 2)  # StupidPositionalEncoder(T_MAX)  #\n",
    "        self.simplified_trans = kwargs['simplified_trans']\n",
    "\n",
    "        enc_net = [kwargs['enc_w']] * kwargs['enc_l']\n",
    "        dec_net = [kwargs['dec_w']] * kwargs['dec_l']\n",
    "        trans_net = [kwargs['trans_w']] * kwargs['trans_l']\n",
    "\n",
    "        if self.CNN:\n",
    "            self.enc = SimpleImageEncoder(self.img_size, self.latent_s, enc_net, t_dim=self.t_emb_s).to(dev)\n",
    "            self.dec = SimpleImageDecoder(self.enc.features_dim, self.latent_s, dec_net, t_dim=self.t_emb_s,\n",
    "                                          out_c=self.img_size[0]).to(dev)\n",
    "        else:\n",
    "            self.dec = TemporalDecoder(32**2, self.latent_s, dec_net, self.t_emb_s).to(dev)\n",
    "            self.enc = TemporalEncoder(32**2, self.latent_s, enc_net, self.t_emb_s).to(dev)\n",
    "\n",
    "        self.trans = TransitionNet(self.latent_s, trans_net, self.t_emb_s).to(dev)\n",
    "        self.dif = DataDiffuser(beta_min=self.beta_min, beta_max=self.beta_max, t_max=self.T_MAX).to(dev)\n",
    "        self.sampling_t0 = False\n",
    "\n",
    "    def loss(self, x0):\n",
    "        if self.sampling_t0:\n",
    "            t0 = torch.randint(0, self.T_MAX - 1, [x0.shape[0]]).to(dev)\n",
    "            x_t0, sigma_x_t0 = self.dif.diffuse(x0, t0, torch.zeros(x0.shape[0]).long().to(dev))\n",
    "        else:\n",
    "            t0 = torch.zeros(x0.shape[0]).to(dev).long()\n",
    "            x_t0 = x0\n",
    "\n",
    "        z_t0 = self.enc(x_t0.view(-1, *self.img_size), self.pos_enc(t0.float().unsqueeze(1)))\n",
    "        # z_t0 = z_t0 + torch.randn(z_t0.shape).to(dev) * (1 - dif.alphas[t0]).sqrt().unsqueeze(1).expand(-1, z_t0.shape[1])\n",
    "        t = torch.torch.distributions.Uniform(t0.float() + 1, torch.ones_like(t0) * self.T_MAX).sample().long().to(dev)\n",
    "\n",
    "        z_t, sigma_z = self.dif.diffuse(z_t0, t, t0)\n",
    "        x_t, sigma_x = self.dif.diffuse(x_t0, t, t0)\n",
    "\n",
    "        mu_x_pred = self.dec(z_t, self.pos_enc(t.float().unsqueeze(1)))\n",
    "        KL_x = ((mu_x_pred - x_t.view(bs, *self.img_size)) ** 2).view(bs, -1).sum(1) / sigma_x ** 2\n",
    "\n",
    "        if self.simplified_trans:\n",
    "            alpha_bar_t = self.dif.alphas[t].unsqueeze(1)#.expand(-1, self.latent_s)\n",
    "            alpha_t = self.dif.alphas_t[t].unsqueeze(1)#.expand(-1, self.latent_s)\n",
    "            beta_t = self.dif.betas[t].unsqueeze(1)#.expand(-1, self.latent_s)\n",
    "\n",
    "            mu_z_pred = (z_t - beta_t/(1-alpha_bar_t).sqrt() * self.trans(z_t, self.pos_enc(t.float().unsqueeze(1))))/alpha_t.sqrt()\n",
    "        else:\n",
    "            mu_z_pred = self.trans(z_t, self.pos_enc(t.float().unsqueeze(1)))\n",
    "        mu, sigma = self.dif.prev_mean(z_t0, z_t, t)\n",
    "\n",
    "        KL_z = ((mu - mu_z_pred) ** 2).sum(1) / sigma ** 2\n",
    "\n",
    "        loss = KL_x.mean(0) + KL_z.mean(0)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.device = device\n",
    "        return self\n",
    "\n",
    "    def sample(self, nb_samples=1):\n",
    "        zT = torch.randn(64, self.latent_s).to(self.device)\n",
    "        z_t = zT\n",
    "        for t in range(self.T_MAX - 1, 0, -1):\n",
    "            t_t = torch.ones(64, 1).to(self.device) * t\n",
    "            if t > 0:\n",
    "                sigma = ((1 - self.dif.alphas[t - 1]) / (1 - self.dif.alphas[t]) * self.dif.betas[t]).sqrt()\n",
    "            else:\n",
    "                sigma = 0\n",
    "            if self.simplified_trans:\n",
    "                alpha_bar_t = self.dif.alphas[t]\n",
    "                alpha_t = self.dif.alphas_t[t]\n",
    "                beta_t = self.dif.betas[t]\n",
    "                mu_z_pred = (z_t - beta_t / (1 - alpha_bar_t).sqrt() * self.trans(z_t, self.pos_enc(t_t))) / alpha_t.sqrt()\n",
    "            else:\n",
    "                mu_z_pred = self.trans(z_t, self.pos_enc(t_t))\n",
    "            z_t = mu_z_pred + torch.randn(z_t.shape, device=self.device) * sigma\n",
    "\n",
    "        x_0 = self.dec(z_t, self.pos_enc(torch.zeros((nb_samples, 1), device=self.device))).view(nb_samples, -1)\n",
    "\n",
    "        return x_0\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=\"latent_diffusion\", entity=\"awehenkel\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bs = 100\n",
    "    config = {\n",
    "        'data': 'MNIST',\n",
    "        'T_MAX': 20,\n",
    "        'latent_s': 60,\n",
    "        't_emb_s': 30,\n",
    "        'CNN': False,\n",
    "        'enc_w': 300,\n",
    "        'enc_l': 4,\n",
    "        'dec_w': 200,\n",
    "        'dec_l': 3,\n",
    "        'trans_w': 200,\n",
    "        'trans_l': 3,\n",
    "        \"beta_min\": 1e-2,\n",
    "        \"beta_max\": .95,\n",
    "        'simplified_trans': True\n",
    "    }\n",
    "    wandb.config.update(config)\n",
    "    train_loader, test_loader = getMNISTDataLoader(bs)\n",
    "    img_size = [1, 32, 32]\n",
    "\n",
    "    # Compute Mean abd std per pixel\n",
    "    x_mean = 0\n",
    "    x_mean2 = 0\n",
    "    for batch_idx, (cur_x, target) in enumerate(train_loader):\n",
    "        cur_x = cur_x.view(bs, -1).float()\n",
    "        x_mean += cur_x.mean(0)\n",
    "        x_mean2 += (cur_x ** 2).mean(0)\n",
    "    x_mean /= batch_idx + 1\n",
    "    x_std = (x_mean2 / (batch_idx + 1) - x_mean ** 2) ** .5\n",
    "    x_std[x_std == 0.] = 1.\n",
    "\n",
    "    dev = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    model = CNNDiffusionModel(**config).to(dev)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, threshold=0.001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n",
    "\n",
    "    wandb.watch(model)\n",
    "    def get_X_back(x):\n",
    "        nb_x = x.shape[0]\n",
    "        x = x * x_std.to(dev).unsqueeze(0).expand(nb_x, -1) + x_mean.to(dev).unsqueeze(0).expand(nb_x, -1)\n",
    "        return logit_back(x)\n",
    "\n",
    "\n",
    "    #sample = list(train_loader)[0][0][[0]].expand(bs, -1, -1, -1)\n",
    "    #save_image(get_X_back(sample.to(dev)[[0]].reshape(1, -1)).reshape(1, 3, 32, 32), './Samples/Generated/sample_rel_' + '.png')\n",
    "    def train(epoch):\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            #data = sample\n",
    "            x0 = data.view(data.shape[0], -1).to(dev)\n",
    "\n",
    "            x0 = (x0 - x_mean.to(dev).unsqueeze(0).expand(bs, -1)) / x_std.to(dev).unsqueeze(0).expand(bs, -1)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model.loss(x0)\n",
    "\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "        samples = get_X_back(model.sample(64)).view(64, *img_size)\n",
    "        save_image(samples, './Samples/Generated/sample_gen_' + str(epoch) + '.png')\n",
    "        scheduler.step(train_loss)\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "        wandb.log({\"Train Loss\": train_loss / len(train_loader.dataset), \"Samples\": [wandb.Image(samples)]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 31.115667\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 20.980425\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 19.927201\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 28.900093\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 25.488660\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 21.631567\n",
      "====> Epoch: 0 Average loss: 22.5364\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 23.405984\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 18.876420\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 18.553192\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 24.401355\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 21.924634\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 17.569568\n",
      "====> Epoch: 1 Average loss: 20.9040\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 28.151648\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 25.509075\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 20.306992\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 18.680603\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 18.621115\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 22.925486\n",
      "====> Epoch: 2 Average loss: 20.3431\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 20.986079\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 19.078202\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 19.987386\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 24.710933\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 26.391831\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 18.516454\n",
      "====> Epoch: 3 Average loss: 20.0035\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 22.574370\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 18.078394\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 24.119548\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 18.744220\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 20.081151\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 19.262407\n",
      "====> Epoch: 4 Average loss: 19.8038\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 18.218389\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 23.729397\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 23.194856\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 26.003450\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 17.638431\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 17.365673\n",
      "====> Epoch: 5 Average loss: 19.7747\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 20.141810\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 18.312013\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 18.012448\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 21.084717\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 17.082256\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 17.697788\n",
      "====> Epoch: 6 Average loss: 19.5918\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 21.063198\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 20.604028\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 19.761809\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 16.712903\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 17.900292\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 19.208643\n",
      "====> Epoch: 7 Average loss: 19.3602\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 20.542263\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 19.578850\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 20.474031\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 18.980682\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 22.008806\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 18.276945\n",
      "====> Epoch: 8 Average loss: 19.4085\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 19.185575\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 21.186941\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 20.580876\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 19.230826\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 18.895525\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 19.705922\n",
      "====> Epoch: 9 Average loss: 19.3569\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 21.523108\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 19.399301\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 15.912604\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 15.824622\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 16.703834\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 19.596479\n",
      "====> Epoch: 10 Average loss: 19.1633\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 21.046343\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 21.041899\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 20.430039\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 17.647775\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 18.015872\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 24.830181\n",
      "====> Epoch: 11 Average loss: 19.1506\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 17.848002\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 19.448226\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 20.057974\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 18.180590\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 18.950837\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 15.763152\n",
      "====> Epoch: 12 Average loss: 19.1768\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 18.816304\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 19.410094\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 21.108572\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 17.604312\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 20.751260\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 19.783779\n",
      "====> Epoch: 13 Average loss: 19.0924\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 18.075120\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 18.046056\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 16.628669\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 18.911796\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 23.557944\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 17.305447\n",
      "====> Epoch: 14 Average loss: 18.9896\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 23.440137\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 19.591066\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 16.727140\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 19.514861\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 21.555217\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 21.047114\n",
      "====> Epoch: 15 Average loss: 19.1124\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 18.956335\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 20.040939\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 17.482828\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 22.032881\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 16.980836\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 14.383188\n",
      "====> Epoch: 16 Average loss: 19.0326\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 18.050454\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 19.968896\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 18.650654\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 15.037108\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 20.799700\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 17.447085\n",
      "====> Epoch: 17 Average loss: 19.0500\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 22.062473\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 19.062583\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 18.178402\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 22.155300\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 18.154377\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 19.044977\n",
      "====> Epoch: 18 Average loss: 19.0802\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 17.652698\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 17.672170\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 18.042128\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 18.745380\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 17.045503\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 16.034741\n",
      "====> Epoch: 19 Average loss: 18.9496\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 21.526311\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 22.022146\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 15.879917\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 18.220336\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 20.078696\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 18.091244\n",
      "====> Epoch: 20 Average loss: 18.8770\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 20.014254\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 19.832942\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 17.465197\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 18.709512\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 18.965654\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 16.414540\n",
      "====> Epoch: 21 Average loss: 18.8360\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 19.153185\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 18.639304\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 20.481011\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 17.168645\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 19.198352\n",
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 21.486921\n",
      "====> Epoch: 22 Average loss: 18.8559\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 14.617941\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 17.116090\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 16.137980\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 19.384039\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 19.986046\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 21.523481\n",
      "====> Epoch: 23 Average loss: 18.6561\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 19.124388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 17.331044\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 17.425044\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 16.777572\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 19.006439\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 17.049421\n",
      "====> Epoch: 24 Average loss: 18.9973\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 17.985801\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 18.688601\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 20.762185\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 19.256757\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 16.668174\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 17.603662\n",
      "====> Epoch: 25 Average loss: 18.7107\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 19.779572\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 22.089622\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 18.952891\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 17.694463\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 19.193444\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 18.844316\n",
      "====> Epoch: 26 Average loss: 18.8158\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 19.623086\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 17.153408\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 21.436794\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 19.577366\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 14.664458\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 22.430518\n",
      "====> Epoch: 27 Average loss: 18.7133\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 17.834160\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 17.343329\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 20.202219\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 17.576195\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 20.650735\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 18.351847\n",
      "====> Epoch: 28 Average loss: 18.8624\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 19.522783\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 16.075544\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 18.435393\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 18.387078\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 16.540284\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 19.336292\n",
      "====> Epoch: 29 Average loss: 18.6395\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 17.277621\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 18.676008\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 18.898478\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 24.149983\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 21.993821\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 16.675256\n",
      "====> Epoch: 30 Average loss: 18.7788\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 15.944966\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 21.145435\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 21.040750\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 20.667959\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 17.445125\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 18.934510\n",
      "====> Epoch: 31 Average loss: 18.7625\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 16.197664\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 16.569028\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 19.181455\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 17.615076\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 20.420974\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 17.790037\n",
      "====> Epoch: 32 Average loss: 18.5210\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 17.158096\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 17.476357\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 16.497610\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 20.109240\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 17.121588\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 19.969209\n",
      "====> Epoch: 33 Average loss: 18.7998\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 17.792371\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 16.534058\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 16.359187\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 17.721760\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 19.087076\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 18.662025\n",
      "====> Epoch: 34 Average loss: 18.7078\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 19.121482\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 25.521113\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 22.229841\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 21.034924\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 18.344012\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 17.641681\n",
      "====> Epoch: 35 Average loss: 18.6770\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 20.919988\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 19.695861\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 20.605945\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 18.485068\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 22.807490\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 17.652368\n",
      "====> Epoch: 36 Average loss: 18.8410\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 19.115660\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 18.245199\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 17.589606\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 20.607676\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 18.401957\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 17.853356\n",
      "====> Epoch: 37 Average loss: 18.5908\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 18.114005\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 20.208163\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 20.882280\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 18.663762\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 17.646371\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 20.028224\n",
      "====> Epoch: 38 Average loss: 18.6667\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 19.082432\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 19.800310\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 19.255006\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 17.733972\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 18.711144\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 18.255194\n",
      "====> Epoch: 39 Average loss: 18.6351\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 18.249934\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 20.184911\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 19.031654\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 18.447859\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 19.098845\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 15.703204\n",
      "====> Epoch: 40 Average loss: 18.8292\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 17.039175\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 17.908865\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 18.623926\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 15.908947\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 21.660173\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 19.221354\n",
      "====> Epoch: 41 Average loss: 18.6465\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 18.595067\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 20.346842\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 18.468879\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 17.459127\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 15.665688\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 17.418994\n",
      "====> Epoch: 42 Average loss: 18.5586\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 17.801027\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 19.082065\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 19.704293\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 18.111100\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 18.985219\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 21.553501\n",
      "Epoch    44: reducing learning rate of group 0 to 5.0000e-04.\n",
      "====> Epoch: 43 Average loss: 18.5445\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 17.882443\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 22.697651\n",
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 20.602429\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 19.256986\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 19.197511\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 18.234768\n",
      "====> Epoch: 44 Average loss: 18.4493\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 16.303260\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 18.375206\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 20.002266\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 16.704397\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 22.811526\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 14.612284\n",
      "====> Epoch: 45 Average loss: 18.4838\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 21.117625\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 14.194504\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 19.241206\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 19.267346\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 19.009528\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 18.438561\n",
      "====> Epoch: 46 Average loss: 18.4389\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 15.246992\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 18.997678\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 18.935699\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 19.204225\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 19.415043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 18.056073\n",
      "====> Epoch: 47 Average loss: 18.4853\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 21.891936\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 18.003358\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 16.921926\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 21.360952\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 22.238164\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 21.913506\n",
      "====> Epoch: 48 Average loss: 18.4847\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 14.740614\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 18.933683\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 19.191704\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 18.402529\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 16.897047\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 16.665353\n",
      "====> Epoch: 49 Average loss: 18.5505\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 18.633685\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 17.680530\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 15.143097\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 16.860419\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 18.325093\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 16.429570\n",
      "====> Epoch: 50 Average loss: 18.5000\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 17.562756\n",
      "Train Epoch: 51 [10000/60000 (17%)]\tLoss: 18.133108\n",
      "Train Epoch: 51 [20000/60000 (33%)]\tLoss: 17.687974\n",
      "Train Epoch: 51 [30000/60000 (50%)]\tLoss: 17.623239\n",
      "Train Epoch: 51 [40000/60000 (67%)]\tLoss: 20.139191\n",
      "Train Epoch: 51 [50000/60000 (83%)]\tLoss: 21.998469\n",
      "====> Epoch: 51 Average loss: 18.4090\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 17.738191\n",
      "Train Epoch: 52 [10000/60000 (17%)]\tLoss: 19.371376\n",
      "Train Epoch: 52 [20000/60000 (33%)]\tLoss: 22.048296\n",
      "Train Epoch: 52 [30000/60000 (50%)]\tLoss: 16.435840\n",
      "Train Epoch: 52 [40000/60000 (67%)]\tLoss: 18.200139\n",
      "Train Epoch: 52 [50000/60000 (83%)]\tLoss: 18.403722\n",
      "====> Epoch: 52 Average loss: 18.3810\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 19.126321\n",
      "Train Epoch: 53 [10000/60000 (17%)]\tLoss: 17.424249\n",
      "Train Epoch: 53 [20000/60000 (33%)]\tLoss: 17.268792\n",
      "Train Epoch: 53 [30000/60000 (50%)]\tLoss: 20.551265\n",
      "Train Epoch: 53 [40000/60000 (67%)]\tLoss: 17.025951\n",
      "Train Epoch: 53 [50000/60000 (83%)]\tLoss: 19.050236\n",
      "====> Epoch: 53 Average loss: 18.3482\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 19.368440\n",
      "Train Epoch: 54 [10000/60000 (17%)]\tLoss: 17.221093\n",
      "Train Epoch: 54 [20000/60000 (33%)]\tLoss: 16.543423\n",
      "Train Epoch: 54 [30000/60000 (50%)]\tLoss: 19.661616\n",
      "Train Epoch: 54 [40000/60000 (67%)]\tLoss: 15.948572\n",
      "Train Epoch: 54 [50000/60000 (83%)]\tLoss: 18.307842\n",
      "====> Epoch: 54 Average loss: 18.4231\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 16.558859\n",
      "Train Epoch: 55 [10000/60000 (17%)]\tLoss: 19.661206\n",
      "Train Epoch: 55 [20000/60000 (33%)]\tLoss: 16.563124\n",
      "Train Epoch: 55 [30000/60000 (50%)]\tLoss: 18.740813\n",
      "Train Epoch: 55 [40000/60000 (67%)]\tLoss: 15.571674\n",
      "Train Epoch: 55 [50000/60000 (83%)]\tLoss: 21.025723\n",
      "====> Epoch: 55 Average loss: 18.3811\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 21.848772\n",
      "Train Epoch: 56 [10000/60000 (17%)]\tLoss: 16.811101\n",
      "Train Epoch: 56 [20000/60000 (33%)]\tLoss: 16.046625\n",
      "Train Epoch: 56 [30000/60000 (50%)]\tLoss: 18.651134\n",
      "Train Epoch: 56 [40000/60000 (67%)]\tLoss: 19.914288\n",
      "Train Epoch: 56 [50000/60000 (83%)]\tLoss: 18.048820\n",
      "====> Epoch: 56 Average loss: 18.3658\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 16.985504\n",
      "Train Epoch: 57 [10000/60000 (17%)]\tLoss: 18.418392\n",
      "Train Epoch: 57 [20000/60000 (33%)]\tLoss: 15.411422\n",
      "Train Epoch: 57 [30000/60000 (50%)]\tLoss: 17.615443\n",
      "Train Epoch: 57 [40000/60000 (67%)]\tLoss: 18.892170\n",
      "Train Epoch: 57 [50000/60000 (83%)]\tLoss: 18.403477\n",
      "====> Epoch: 57 Average loss: 18.3847\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 19.915840\n",
      "Train Epoch: 58 [10000/60000 (17%)]\tLoss: 17.594956\n",
      "Train Epoch: 58 [20000/60000 (33%)]\tLoss: 20.726553\n",
      "Train Epoch: 58 [30000/60000 (50%)]\tLoss: 20.757473\n",
      "Train Epoch: 58 [40000/60000 (67%)]\tLoss: 18.875535\n",
      "Train Epoch: 58 [50000/60000 (83%)]\tLoss: 20.500718\n",
      "====> Epoch: 58 Average loss: 18.4083\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 18.262717\n",
      "Train Epoch: 59 [10000/60000 (17%)]\tLoss: 22.566208\n",
      "Train Epoch: 59 [20000/60000 (33%)]\tLoss: 14.183809\n",
      "Train Epoch: 59 [30000/60000 (50%)]\tLoss: 17.388767\n",
      "Train Epoch: 59 [40000/60000 (67%)]\tLoss: 18.720841\n",
      "Train Epoch: 59 [50000/60000 (83%)]\tLoss: 19.979786\n",
      "====> Epoch: 59 Average loss: 18.3994\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 15.632565\n",
      "Train Epoch: 60 [10000/60000 (17%)]\tLoss: 16.461901\n",
      "Train Epoch: 60 [20000/60000 (33%)]\tLoss: 16.470438\n",
      "Train Epoch: 60 [30000/60000 (50%)]\tLoss: 21.963286\n",
      "Train Epoch: 60 [40000/60000 (67%)]\tLoss: 16.927197\n",
      "Train Epoch: 60 [50000/60000 (83%)]\tLoss: 18.138402\n",
      "====> Epoch: 60 Average loss: 18.3830\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 22.637627\n",
      "Train Epoch: 61 [10000/60000 (17%)]\tLoss: 16.881121\n",
      "Train Epoch: 61 [20000/60000 (33%)]\tLoss: 17.332284\n",
      "Train Epoch: 61 [30000/60000 (50%)]\tLoss: 24.163450\n",
      "Train Epoch: 61 [40000/60000 (67%)]\tLoss: 18.404410\n",
      "Train Epoch: 61 [50000/60000 (83%)]\tLoss: 16.627212\n",
      "====> Epoch: 61 Average loss: 18.3249\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 17.081061\n",
      "Train Epoch: 62 [10000/60000 (17%)]\tLoss: 21.635054\n",
      "Train Epoch: 62 [20000/60000 (33%)]\tLoss: 19.347457\n",
      "Train Epoch: 62 [30000/60000 (50%)]\tLoss: 17.960791\n",
      "Train Epoch: 62 [40000/60000 (67%)]\tLoss: 18.203885\n",
      "Train Epoch: 62 [50000/60000 (83%)]\tLoss: 19.921947\n",
      "====> Epoch: 62 Average loss: 18.2833\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 18.460070\n",
      "Train Epoch: 63 [10000/60000 (17%)]\tLoss: 13.886068\n",
      "Train Epoch: 63 [20000/60000 (33%)]\tLoss: 21.239275\n",
      "Train Epoch: 63 [30000/60000 (50%)]\tLoss: 18.266189\n",
      "Train Epoch: 63 [40000/60000 (67%)]\tLoss: 17.897343\n",
      "Train Epoch: 63 [50000/60000 (83%)]\tLoss: 18.959406\n",
      "====> Epoch: 63 Average loss: 18.4154\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 19.397240\n",
      "Train Epoch: 64 [10000/60000 (17%)]\tLoss: 19.391188\n",
      "Train Epoch: 64 [20000/60000 (33%)]\tLoss: 21.347974\n",
      "Train Epoch: 64 [30000/60000 (50%)]\tLoss: 19.706028\n",
      "Train Epoch: 64 [40000/60000 (67%)]\tLoss: 19.409016\n",
      "Train Epoch: 64 [50000/60000 (83%)]\tLoss: 16.415192\n",
      "====> Epoch: 64 Average loss: 18.2741\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 17.106017\n",
      "Train Epoch: 65 [10000/60000 (17%)]\tLoss: 17.737037\n",
      "Train Epoch: 65 [20000/60000 (33%)]\tLoss: 22.597427\n",
      "Train Epoch: 65 [30000/60000 (50%)]\tLoss: 17.314873\n",
      "Train Epoch: 65 [40000/60000 (67%)]\tLoss: 18.383127\n",
      "Train Epoch: 65 [50000/60000 (83%)]\tLoss: 16.910153\n",
      "====> Epoch: 65 Average loss: 18.2993\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 15.799626\n",
      "Train Epoch: 66 [10000/60000 (17%)]\tLoss: 17.309714\n",
      "Train Epoch: 66 [20000/60000 (33%)]\tLoss: 16.230934\n",
      "Train Epoch: 66 [30000/60000 (50%)]\tLoss: 16.338623\n",
      "Train Epoch: 66 [40000/60000 (67%)]\tLoss: 16.067782\n",
      "Train Epoch: 66 [50000/60000 (83%)]\tLoss: 15.754266\n",
      "====> Epoch: 66 Average loss: 18.1949\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 18.747375\n",
      "Train Epoch: 67 [10000/60000 (17%)]\tLoss: 17.541447\n",
      "Train Epoch: 67 [20000/60000 (33%)]\tLoss: 18.471526\n",
      "Train Epoch: 67 [30000/60000 (50%)]\tLoss: 16.921384\n",
      "Train Epoch: 67 [40000/60000 (67%)]\tLoss: 19.384521\n",
      "Train Epoch: 67 [50000/60000 (83%)]\tLoss: 16.520482\n",
      "====> Epoch: 67 Average loss: 18.2880\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 19.458708\n",
      "Train Epoch: 68 [10000/60000 (17%)]\tLoss: 19.659451\n",
      "Train Epoch: 68 [20000/60000 (33%)]\tLoss: 17.467285\n",
      "Train Epoch: 68 [30000/60000 (50%)]\tLoss: 20.465612\n",
      "Train Epoch: 68 [40000/60000 (67%)]\tLoss: 16.475548\n",
      "Train Epoch: 68 [50000/60000 (83%)]\tLoss: 18.320593\n",
      "====> Epoch: 68 Average loss: 18.3639\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 16.903103\n",
      "Train Epoch: 69 [10000/60000 (17%)]\tLoss: 19.390944\n",
      "Train Epoch: 69 [20000/60000 (33%)]\tLoss: 14.124659\n",
      "Train Epoch: 69 [30000/60000 (50%)]\tLoss: 21.195396\n",
      "Train Epoch: 69 [40000/60000 (67%)]\tLoss: 18.835280\n",
      "Train Epoch: 69 [50000/60000 (83%)]\tLoss: 14.989932\n",
      "====> Epoch: 69 Average loss: 18.2075\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 19.380344\n",
      "Train Epoch: 70 [10000/60000 (17%)]\tLoss: 19.633510\n",
      "Train Epoch: 70 [20000/60000 (33%)]\tLoss: 19.146007\n",
      "Train Epoch: 70 [30000/60000 (50%)]\tLoss: 16.925205\n",
      "Train Epoch: 70 [40000/60000 (67%)]\tLoss: 20.971516\n",
      "Train Epoch: 70 [50000/60000 (83%)]\tLoss: 21.327417\n",
      "====> Epoch: 70 Average loss: 18.2772\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 17.217239\n",
      "Train Epoch: 71 [10000/60000 (17%)]\tLoss: 19.315374\n",
      "Train Epoch: 71 [20000/60000 (33%)]\tLoss: 20.769277\n",
      "Train Epoch: 71 [30000/60000 (50%)]\tLoss: 19.328428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71 [40000/60000 (67%)]\tLoss: 19.706300\n",
      "Train Epoch: 71 [50000/60000 (83%)]\tLoss: 17.849021\n",
      "====> Epoch: 71 Average loss: 18.3173\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 16.067274\n",
      "Train Epoch: 72 [10000/60000 (17%)]\tLoss: 14.322343\n",
      "Train Epoch: 72 [20000/60000 (33%)]\tLoss: 20.539160\n",
      "Train Epoch: 72 [30000/60000 (50%)]\tLoss: 17.987850\n",
      "Train Epoch: 72 [40000/60000 (67%)]\tLoss: 18.568621\n",
      "Train Epoch: 72 [50000/60000 (83%)]\tLoss: 17.493661\n",
      "====> Epoch: 72 Average loss: 18.2863\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 18.451920\n",
      "Train Epoch: 73 [10000/60000 (17%)]\tLoss: 15.756941\n",
      "Train Epoch: 73 [20000/60000 (33%)]\tLoss: 17.208945\n",
      "Train Epoch: 73 [30000/60000 (50%)]\tLoss: 20.346716\n",
      "Train Epoch: 73 [40000/60000 (67%)]\tLoss: 20.052485\n",
      "Train Epoch: 73 [50000/60000 (83%)]\tLoss: 15.448701\n",
      "====> Epoch: 73 Average loss: 18.3271\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 20.874512\n",
      "Train Epoch: 74 [10000/60000 (17%)]\tLoss: 19.658965\n",
      "Train Epoch: 74 [20000/60000 (33%)]\tLoss: 19.871985\n",
      "Train Epoch: 74 [30000/60000 (50%)]\tLoss: 18.685151\n",
      "Train Epoch: 74 [40000/60000 (67%)]\tLoss: 17.124507\n",
      "Train Epoch: 74 [50000/60000 (83%)]\tLoss: 17.756429\n",
      "====> Epoch: 74 Average loss: 18.3183\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 21.358032\n",
      "Train Epoch: 75 [10000/60000 (17%)]\tLoss: 17.329252\n",
      "Train Epoch: 75 [20000/60000 (33%)]\tLoss: 20.707776\n",
      "Train Epoch: 75 [30000/60000 (50%)]\tLoss: 19.357411\n",
      "Train Epoch: 75 [40000/60000 (67%)]\tLoss: 18.184969\n",
      "Train Epoch: 75 [50000/60000 (83%)]\tLoss: 17.615181\n",
      "====> Epoch: 75 Average loss: 18.2962\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 17.589670\n",
      "Train Epoch: 76 [10000/60000 (17%)]\tLoss: 18.119106\n",
      "Train Epoch: 76 [20000/60000 (33%)]\tLoss: 25.302671\n",
      "Train Epoch: 76 [30000/60000 (50%)]\tLoss: 18.675355\n",
      "Train Epoch: 76 [40000/60000 (67%)]\tLoss: 18.557504\n",
      "Train Epoch: 76 [50000/60000 (83%)]\tLoss: 16.021676\n",
      "====> Epoch: 76 Average loss: 18.3948\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 16.979999\n",
      "Train Epoch: 77 [10000/60000 (17%)]\tLoss: 20.460195\n",
      "Train Epoch: 77 [20000/60000 (33%)]\tLoss: 19.437372\n",
      "Train Epoch: 77 [30000/60000 (50%)]\tLoss: 19.125127\n",
      "Train Epoch: 77 [40000/60000 (67%)]\tLoss: 16.024646\n",
      "Train Epoch: 77 [50000/60000 (83%)]\tLoss: 18.889355\n",
      "Epoch    78: reducing learning rate of group 0 to 2.5000e-04.\n",
      "====> Epoch: 77 Average loss: 18.1975\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 19.483856\n",
      "Train Epoch: 78 [10000/60000 (17%)]\tLoss: 17.747815\n",
      "Train Epoch: 78 [20000/60000 (33%)]\tLoss: 17.370721\n",
      "Train Epoch: 78 [30000/60000 (50%)]\tLoss: 18.940161\n",
      "Train Epoch: 78 [40000/60000 (67%)]\tLoss: 21.008267\n",
      "Train Epoch: 78 [50000/60000 (83%)]\tLoss: 19.586301\n",
      "====> Epoch: 78 Average loss: 18.2459\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 15.441077\n",
      "Train Epoch: 79 [10000/60000 (17%)]\tLoss: 14.539867\n",
      "Train Epoch: 79 [20000/60000 (33%)]\tLoss: 18.497948\n",
      "Train Epoch: 79 [30000/60000 (50%)]\tLoss: 16.917881\n",
      "Train Epoch: 79 [40000/60000 (67%)]\tLoss: 17.306296\n",
      "Train Epoch: 79 [50000/60000 (83%)]\tLoss: 19.567152\n",
      "====> Epoch: 79 Average loss: 18.1752\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 17.315519\n",
      "Train Epoch: 80 [10000/60000 (17%)]\tLoss: 18.698331\n",
      "Train Epoch: 80 [20000/60000 (33%)]\tLoss: 16.678625\n",
      "Train Epoch: 80 [30000/60000 (50%)]\tLoss: 19.795566\n",
      "Train Epoch: 80 [40000/60000 (67%)]\tLoss: 19.503600\n",
      "Train Epoch: 80 [50000/60000 (83%)]\tLoss: 19.132560\n",
      "====> Epoch: 80 Average loss: 18.3067\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 16.647930\n",
      "Train Epoch: 81 [10000/60000 (17%)]\tLoss: 17.374618\n",
      "Train Epoch: 81 [20000/60000 (33%)]\tLoss: 17.990996\n",
      "Train Epoch: 81 [30000/60000 (50%)]\tLoss: 16.534440\n",
      "Train Epoch: 81 [40000/60000 (67%)]\tLoss: 18.051958\n",
      "Train Epoch: 81 [50000/60000 (83%)]\tLoss: 19.448662\n",
      "====> Epoch: 81 Average loss: 18.1817\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 17.875267\n",
      "Train Epoch: 82 [10000/60000 (17%)]\tLoss: 17.962144\n",
      "Train Epoch: 82 [20000/60000 (33%)]\tLoss: 14.202041\n",
      "Train Epoch: 82 [30000/60000 (50%)]\tLoss: 19.683132\n",
      "Train Epoch: 82 [40000/60000 (67%)]\tLoss: 22.146877\n",
      "Train Epoch: 82 [50000/60000 (83%)]\tLoss: 17.908567\n",
      "====> Epoch: 82 Average loss: 18.0927\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 20.149562\n",
      "Train Epoch: 83 [10000/60000 (17%)]\tLoss: 16.045974\n",
      "Train Epoch: 83 [20000/60000 (33%)]\tLoss: 16.913055\n",
      "Train Epoch: 83 [30000/60000 (50%)]\tLoss: 17.197782\n",
      "Train Epoch: 83 [40000/60000 (67%)]\tLoss: 17.632091\n",
      "Train Epoch: 83 [50000/60000 (83%)]\tLoss: 17.449326\n",
      "====> Epoch: 83 Average loss: 18.1907\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 16.826335\n",
      "Train Epoch: 84 [10000/60000 (17%)]\tLoss: 19.423425\n",
      "Train Epoch: 84 [20000/60000 (33%)]\tLoss: 19.005284\n",
      "Train Epoch: 84 [30000/60000 (50%)]\tLoss: 17.163038\n",
      "Train Epoch: 84 [40000/60000 (67%)]\tLoss: 18.277959\n",
      "Train Epoch: 84 [50000/60000 (83%)]\tLoss: 16.796481\n",
      "====> Epoch: 84 Average loss: 18.1600\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 19.729746\n",
      "Train Epoch: 85 [10000/60000 (17%)]\tLoss: 16.388228\n",
      "Train Epoch: 85 [20000/60000 (33%)]\tLoss: 17.844438\n",
      "Train Epoch: 85 [30000/60000 (50%)]\tLoss: 20.014216\n",
      "Train Epoch: 85 [40000/60000 (67%)]\tLoss: 19.539020\n",
      "Train Epoch: 85 [50000/60000 (83%)]\tLoss: 16.985548\n",
      "====> Epoch: 85 Average loss: 18.1878\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 18.468661\n",
      "Train Epoch: 86 [10000/60000 (17%)]\tLoss: 15.165636\n",
      "Train Epoch: 86 [20000/60000 (33%)]\tLoss: 19.053033\n",
      "Train Epoch: 86 [30000/60000 (50%)]\tLoss: 20.616863\n",
      "Train Epoch: 86 [40000/60000 (67%)]\tLoss: 18.705090\n",
      "Train Epoch: 86 [50000/60000 (83%)]\tLoss: 18.985455\n",
      "====> Epoch: 86 Average loss: 18.1455\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 18.445743\n",
      "Train Epoch: 87 [10000/60000 (17%)]\tLoss: 20.542246\n",
      "Train Epoch: 87 [20000/60000 (33%)]\tLoss: 17.482789\n",
      "Train Epoch: 87 [30000/60000 (50%)]\tLoss: 19.398497\n",
      "Train Epoch: 87 [40000/60000 (67%)]\tLoss: 16.268401\n",
      "Train Epoch: 87 [50000/60000 (83%)]\tLoss: 18.420133\n",
      "====> Epoch: 87 Average loss: 18.3201\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 22.085325\n",
      "Train Epoch: 88 [10000/60000 (17%)]\tLoss: 16.798999\n",
      "Train Epoch: 88 [20000/60000 (33%)]\tLoss: 15.585006\n",
      "Train Epoch: 88 [30000/60000 (50%)]\tLoss: 16.058069\n",
      "Train Epoch: 88 [40000/60000 (67%)]\tLoss: 15.220070\n",
      "Train Epoch: 88 [50000/60000 (83%)]\tLoss: 17.743113\n",
      "====> Epoch: 88 Average loss: 18.2089\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 18.561552\n",
      "Train Epoch: 89 [10000/60000 (17%)]\tLoss: 15.593971\n",
      "Train Epoch: 89 [20000/60000 (33%)]\tLoss: 17.094315\n",
      "Train Epoch: 89 [30000/60000 (50%)]\tLoss: 20.299539\n",
      "Train Epoch: 89 [40000/60000 (67%)]\tLoss: 19.576952\n",
      "Train Epoch: 89 [50000/60000 (83%)]\tLoss: 20.723652\n",
      "====> Epoch: 89 Average loss: 18.0474\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 18.368059\n",
      "Train Epoch: 90 [10000/60000 (17%)]\tLoss: 21.547876\n",
      "Train Epoch: 90 [20000/60000 (33%)]\tLoss: 18.373562\n",
      "Train Epoch: 90 [30000/60000 (50%)]\tLoss: 18.603861\n",
      "Train Epoch: 90 [40000/60000 (67%)]\tLoss: 19.910355\n",
      "Train Epoch: 90 [50000/60000 (83%)]\tLoss: 17.601376\n",
      "====> Epoch: 90 Average loss: 18.1697\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 17.540969\n",
      "Train Epoch: 91 [10000/60000 (17%)]\tLoss: 18.356428\n",
      "Train Epoch: 91 [20000/60000 (33%)]\tLoss: 18.496373\n",
      "Train Epoch: 91 [30000/60000 (50%)]\tLoss: 22.221599\n",
      "Train Epoch: 91 [40000/60000 (67%)]\tLoss: 17.551057\n",
      "Train Epoch: 91 [50000/60000 (83%)]\tLoss: 18.356067\n",
      "====> Epoch: 91 Average loss: 18.1798\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 14.081145\n",
      "Train Epoch: 92 [10000/60000 (17%)]\tLoss: 15.862498\n",
      "Train Epoch: 92 [20000/60000 (33%)]\tLoss: 18.795438\n",
      "Train Epoch: 92 [30000/60000 (50%)]\tLoss: 19.801558\n",
      "Train Epoch: 92 [40000/60000 (67%)]\tLoss: 22.265103\n",
      "Train Epoch: 92 [50000/60000 (83%)]\tLoss: 20.798374\n",
      "====> Epoch: 92 Average loss: 18.3266\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 14.531238\n",
      "Train Epoch: 93 [10000/60000 (17%)]\tLoss: 17.477213\n",
      "Train Epoch: 93 [20000/60000 (33%)]\tLoss: 19.749135\n",
      "Train Epoch: 93 [30000/60000 (50%)]\tLoss: 17.805336\n",
      "Train Epoch: 93 [40000/60000 (67%)]\tLoss: 16.551248\n",
      "Train Epoch: 93 [50000/60000 (83%)]\tLoss: 21.548486\n",
      "====> Epoch: 93 Average loss: 18.3122\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 19.561372\n",
      "Train Epoch: 94 [10000/60000 (17%)]\tLoss: 14.759513\n",
      "Train Epoch: 94 [20000/60000 (33%)]\tLoss: 20.362693\n",
      "Train Epoch: 94 [30000/60000 (50%)]\tLoss: 15.016825\n",
      "Train Epoch: 94 [40000/60000 (67%)]\tLoss: 18.044708\n",
      "Train Epoch: 94 [50000/60000 (83%)]\tLoss: 19.191643\n",
      "====> Epoch: 94 Average loss: 18.2527\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 18.547953\n",
      "Train Epoch: 95 [10000/60000 (17%)]\tLoss: 14.665663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 95 [20000/60000 (33%)]\tLoss: 17.730042\n",
      "Train Epoch: 95 [30000/60000 (50%)]\tLoss: 17.813217\n",
      "Train Epoch: 95 [40000/60000 (67%)]\tLoss: 15.738013\n",
      "Train Epoch: 95 [50000/60000 (83%)]\tLoss: 20.709387\n",
      "====> Epoch: 95 Average loss: 18.1814\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 17.052660\n",
      "Train Epoch: 96 [10000/60000 (17%)]\tLoss: 19.269821\n",
      "Train Epoch: 96 [20000/60000 (33%)]\tLoss: 18.353818\n",
      "Train Epoch: 96 [30000/60000 (50%)]\tLoss: 20.630769\n",
      "Train Epoch: 96 [40000/60000 (67%)]\tLoss: 22.184312\n",
      "Train Epoch: 96 [50000/60000 (83%)]\tLoss: 18.247047\n",
      "====> Epoch: 96 Average loss: 18.2038\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 15.285146\n",
      "Train Epoch: 97 [10000/60000 (17%)]\tLoss: 17.706404\n",
      "Train Epoch: 97 [20000/60000 (33%)]\tLoss: 16.948573\n",
      "Train Epoch: 97 [30000/60000 (50%)]\tLoss: 19.307715\n",
      "Train Epoch: 97 [40000/60000 (67%)]\tLoss: 16.193920\n",
      "Train Epoch: 97 [50000/60000 (83%)]\tLoss: 16.682319\n",
      "====> Epoch: 97 Average loss: 18.1677\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 18.686443\n",
      "Train Epoch: 98 [10000/60000 (17%)]\tLoss: 19.807747\n",
      "Train Epoch: 98 [20000/60000 (33%)]\tLoss: 20.904846\n",
      "Train Epoch: 98 [30000/60000 (50%)]\tLoss: 19.005432\n",
      "Train Epoch: 98 [40000/60000 (67%)]\tLoss: 16.902927\n",
      "Train Epoch: 98 [50000/60000 (83%)]\tLoss: 16.234191\n",
      "====> Epoch: 98 Average loss: 18.1993\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 17.837151\n",
      "Train Epoch: 99 [10000/60000 (17%)]\tLoss: 19.445801\n",
      "Train Epoch: 99 [20000/60000 (33%)]\tLoss: 17.588081\n",
      "Train Epoch: 99 [30000/60000 (50%)]\tLoss: 17.932714\n",
      "Train Epoch: 99 [40000/60000 (67%)]\tLoss: 15.759469\n",
      "Train Epoch: 99 [50000/60000 (83%)]\tLoss: 21.520234\n",
      "====> Epoch: 99 Average loss: 18.0573\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 18.778064\n",
      "Train Epoch: 100 [10000/60000 (17%)]\tLoss: 16.425795\n",
      "Train Epoch: 100 [20000/60000 (33%)]\tLoss: 19.881173\n",
      "Train Epoch: 100 [30000/60000 (50%)]\tLoss: 18.890240\n",
      "Train Epoch: 100 [40000/60000 (67%)]\tLoss: 16.902145\n",
      "Train Epoch: 100 [50000/60000 (83%)]\tLoss: 16.785149\n",
      "Epoch   101: reducing learning rate of group 0 to 1.2500e-04.\n",
      "====> Epoch: 100 Average loss: 18.1924\n",
      "Train Epoch: 101 [0/60000 (0%)]\tLoss: 18.109293\n",
      "Train Epoch: 101 [10000/60000 (17%)]\tLoss: 16.660166\n",
      "Train Epoch: 101 [20000/60000 (33%)]\tLoss: 17.191720\n",
      "Train Epoch: 101 [30000/60000 (50%)]\tLoss: 16.433213\n",
      "Train Epoch: 101 [40000/60000 (67%)]\tLoss: 16.237195\n",
      "Train Epoch: 101 [50000/60000 (83%)]\tLoss: 20.451910\n",
      "====> Epoch: 101 Average loss: 18.0349\n",
      "Train Epoch: 102 [0/60000 (0%)]\tLoss: 18.620526\n",
      "Train Epoch: 102 [10000/60000 (17%)]\tLoss: 19.117357\n",
      "Train Epoch: 102 [20000/60000 (33%)]\tLoss: 17.796979\n",
      "Train Epoch: 102 [30000/60000 (50%)]\tLoss: 20.519226\n",
      "Train Epoch: 102 [40000/60000 (67%)]\tLoss: 19.038367\n",
      "Train Epoch: 102 [50000/60000 (83%)]\tLoss: 19.343938\n",
      "====> Epoch: 102 Average loss: 17.9586\n",
      "Train Epoch: 103 [0/60000 (0%)]\tLoss: 16.919672\n",
      "Train Epoch: 103 [10000/60000 (17%)]\tLoss: 16.756096\n",
      "Train Epoch: 103 [20000/60000 (33%)]\tLoss: 22.264028\n",
      "Train Epoch: 103 [30000/60000 (50%)]\tLoss: 17.400100\n",
      "Train Epoch: 103 [40000/60000 (67%)]\tLoss: 14.689100\n",
      "Train Epoch: 103 [50000/60000 (83%)]\tLoss: 17.500634\n",
      "====> Epoch: 103 Average loss: 18.1697\n",
      "Train Epoch: 104 [0/60000 (0%)]\tLoss: 15.663365\n",
      "Train Epoch: 104 [10000/60000 (17%)]\tLoss: 21.826042\n",
      "Train Epoch: 104 [20000/60000 (33%)]\tLoss: 21.426582\n",
      "Train Epoch: 104 [30000/60000 (50%)]\tLoss: 20.257294\n",
      "Train Epoch: 104 [40000/60000 (67%)]\tLoss: 22.035134\n",
      "Train Epoch: 104 [50000/60000 (83%)]\tLoss: 17.421315\n",
      "====> Epoch: 104 Average loss: 18.1500\n",
      "Train Epoch: 105 [0/60000 (0%)]\tLoss: 18.445126\n",
      "Train Epoch: 105 [10000/60000 (17%)]\tLoss: 16.996948\n",
      "Train Epoch: 105 [20000/60000 (33%)]\tLoss: 18.215690\n",
      "Train Epoch: 105 [30000/60000 (50%)]\tLoss: 18.331847\n",
      "Train Epoch: 105 [40000/60000 (67%)]\tLoss: 20.180845\n",
      "Train Epoch: 105 [50000/60000 (83%)]\tLoss: 17.073250\n",
      "====> Epoch: 105 Average loss: 18.0078\n",
      "Train Epoch: 106 [0/60000 (0%)]\tLoss: 19.425902\n",
      "Train Epoch: 106 [10000/60000 (17%)]\tLoss: 19.900961\n",
      "Train Epoch: 106 [20000/60000 (33%)]\tLoss: 17.016713\n",
      "Train Epoch: 106 [30000/60000 (50%)]\tLoss: 20.287587\n",
      "Train Epoch: 106 [40000/60000 (67%)]\tLoss: 18.115095\n",
      "Train Epoch: 106 [50000/60000 (83%)]\tLoss: 15.534102\n",
      "====> Epoch: 106 Average loss: 18.1500\n",
      "Train Epoch: 107 [0/60000 (0%)]\tLoss: 18.817003\n",
      "Train Epoch: 107 [10000/60000 (17%)]\tLoss: 16.915703\n",
      "Train Epoch: 107 [20000/60000 (33%)]\tLoss: 15.674797\n",
      "Train Epoch: 107 [30000/60000 (50%)]\tLoss: 17.259048\n",
      "Train Epoch: 107 [40000/60000 (67%)]\tLoss: 16.206929\n",
      "Train Epoch: 107 [50000/60000 (83%)]\tLoss: 17.780226\n",
      "====> Epoch: 107 Average loss: 18.1380\n",
      "Train Epoch: 108 [0/60000 (0%)]\tLoss: 17.953582\n",
      "Train Epoch: 108 [10000/60000 (17%)]\tLoss: 18.848287\n",
      "Train Epoch: 108 [20000/60000 (33%)]\tLoss: 18.864679\n",
      "Train Epoch: 108 [30000/60000 (50%)]\tLoss: 20.287408\n",
      "Train Epoch: 108 [40000/60000 (67%)]\tLoss: 16.756580\n",
      "Train Epoch: 108 [50000/60000 (83%)]\tLoss: 14.446310\n",
      "====> Epoch: 108 Average loss: 18.1894\n",
      "Train Epoch: 109 [0/60000 (0%)]\tLoss: 21.294280\n",
      "Train Epoch: 109 [10000/60000 (17%)]\tLoss: 20.136110\n",
      "Train Epoch: 109 [20000/60000 (33%)]\tLoss: 18.093938\n",
      "Train Epoch: 109 [30000/60000 (50%)]\tLoss: 18.396934\n",
      "Train Epoch: 109 [40000/60000 (67%)]\tLoss: 15.572795\n",
      "Train Epoch: 109 [50000/60000 (83%)]\tLoss: 13.388561\n",
      "====> Epoch: 109 Average loss: 18.0725\n",
      "Train Epoch: 110 [0/60000 (0%)]\tLoss: 19.077786\n",
      "Train Epoch: 110 [10000/60000 (17%)]\tLoss: 19.029045\n",
      "Train Epoch: 110 [20000/60000 (33%)]\tLoss: 15.178279\n",
      "Train Epoch: 110 [30000/60000 (50%)]\tLoss: 18.521382\n",
      "Train Epoch: 110 [40000/60000 (67%)]\tLoss: 16.163495\n",
      "Train Epoch: 110 [50000/60000 (83%)]\tLoss: 16.215289\n",
      "====> Epoch: 110 Average loss: 18.1793\n",
      "Train Epoch: 111 [0/60000 (0%)]\tLoss: 21.383311\n",
      "Train Epoch: 111 [10000/60000 (17%)]\tLoss: 19.937034\n",
      "Train Epoch: 111 [20000/60000 (33%)]\tLoss: 17.913019\n",
      "Train Epoch: 111 [30000/60000 (50%)]\tLoss: 18.513104\n",
      "Train Epoch: 111 [40000/60000 (67%)]\tLoss: 19.451344\n",
      "Train Epoch: 111 [50000/60000 (83%)]\tLoss: 17.773647\n",
      "====> Epoch: 111 Average loss: 18.3087\n",
      "Train Epoch: 112 [0/60000 (0%)]\tLoss: 18.823966\n",
      "Train Epoch: 112 [10000/60000 (17%)]\tLoss: 19.651558\n",
      "Train Epoch: 112 [20000/60000 (33%)]\tLoss: 21.185396\n",
      "Train Epoch: 112 [30000/60000 (50%)]\tLoss: 22.695422\n",
      "Train Epoch: 112 [40000/60000 (67%)]\tLoss: 20.496050\n",
      "Train Epoch: 112 [50000/60000 (83%)]\tLoss: 18.887472\n",
      "====> Epoch: 112 Average loss: 18.1847\n",
      "Train Epoch: 113 [0/60000 (0%)]\tLoss: 18.702406\n",
      "Train Epoch: 113 [10000/60000 (17%)]\tLoss: 19.607870\n",
      "Train Epoch: 113 [20000/60000 (33%)]\tLoss: 16.243427\n",
      "Train Epoch: 113 [30000/60000 (50%)]\tLoss: 16.392308\n",
      "Train Epoch: 113 [40000/60000 (67%)]\tLoss: 21.752632\n",
      "Train Epoch: 113 [50000/60000 (83%)]\tLoss: 16.751029\n",
      "Epoch   114: reducing learning rate of group 0 to 6.2500e-05.\n",
      "====> Epoch: 113 Average loss: 18.1200\n",
      "Train Epoch: 114 [0/60000 (0%)]\tLoss: 16.237694\n",
      "Train Epoch: 114 [10000/60000 (17%)]\tLoss: 21.584968\n",
      "Train Epoch: 114 [20000/60000 (33%)]\tLoss: 15.491290\n",
      "Train Epoch: 114 [30000/60000 (50%)]\tLoss: 15.804216\n",
      "Train Epoch: 114 [40000/60000 (67%)]\tLoss: 15.329282\n",
      "Train Epoch: 114 [50000/60000 (83%)]\tLoss: 18.001694\n",
      "====> Epoch: 114 Average loss: 18.0155\n",
      "Train Epoch: 115 [0/60000 (0%)]\tLoss: 17.705358\n",
      "Train Epoch: 115 [10000/60000 (17%)]\tLoss: 15.259559\n",
      "Train Epoch: 115 [20000/60000 (33%)]\tLoss: 16.953986\n",
      "Train Epoch: 115 [30000/60000 (50%)]\tLoss: 16.694441\n",
      "Train Epoch: 115 [40000/60000 (67%)]\tLoss: 16.650044\n",
      "Train Epoch: 115 [50000/60000 (83%)]\tLoss: 17.259321\n",
      "====> Epoch: 115 Average loss: 18.0229\n",
      "Train Epoch: 116 [0/60000 (0%)]\tLoss: 16.278159\n",
      "Train Epoch: 116 [10000/60000 (17%)]\tLoss: 17.302629\n",
      "Train Epoch: 116 [20000/60000 (33%)]\tLoss: 15.691903\n",
      "Train Epoch: 116 [30000/60000 (50%)]\tLoss: 16.361699\n",
      "Train Epoch: 116 [40000/60000 (67%)]\tLoss: 16.811531\n",
      "Train Epoch: 116 [50000/60000 (83%)]\tLoss: 16.711907\n",
      "====> Epoch: 116 Average loss: 18.2021\n",
      "Train Epoch: 117 [0/60000 (0%)]\tLoss: 18.696075\n",
      "Train Epoch: 117 [10000/60000 (17%)]\tLoss: 16.290895\n",
      "Train Epoch: 117 [20000/60000 (33%)]\tLoss: 15.518795\n",
      "Train Epoch: 117 [30000/60000 (50%)]\tLoss: 18.914320\n",
      "Train Epoch: 117 [40000/60000 (67%)]\tLoss: 17.455153\n",
      "Train Epoch: 117 [50000/60000 (83%)]\tLoss: 16.484517\n",
      "====> Epoch: 117 Average loss: 18.2237\n",
      "Train Epoch: 118 [0/60000 (0%)]\tLoss: 14.630688\n",
      "Train Epoch: 118 [10000/60000 (17%)]\tLoss: 16.920837\n",
      "Train Epoch: 118 [20000/60000 (33%)]\tLoss: 17.464899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 118 [30000/60000 (50%)]\tLoss: 18.174150\n",
      "Train Epoch: 118 [40000/60000 (67%)]\tLoss: 17.407310\n",
      "Train Epoch: 118 [50000/60000 (83%)]\tLoss: 18.139017\n",
      "====> Epoch: 118 Average loss: 18.1465\n",
      "Train Epoch: 119 [0/60000 (0%)]\tLoss: 16.069698\n",
      "Train Epoch: 119 [10000/60000 (17%)]\tLoss: 18.437675\n",
      "Train Epoch: 119 [20000/60000 (33%)]\tLoss: 17.095336\n",
      "Train Epoch: 119 [30000/60000 (50%)]\tLoss: 19.071021\n",
      "Train Epoch: 119 [40000/60000 (67%)]\tLoss: 15.007584\n",
      "Train Epoch: 119 [50000/60000 (83%)]\tLoss: 15.246648\n",
      "====> Epoch: 119 Average loss: 18.0683\n",
      "Train Epoch: 120 [0/60000 (0%)]\tLoss: 17.140422\n",
      "Train Epoch: 120 [10000/60000 (17%)]\tLoss: 16.315746\n",
      "Train Epoch: 120 [20000/60000 (33%)]\tLoss: 17.970836\n",
      "Train Epoch: 120 [30000/60000 (50%)]\tLoss: 16.482283\n",
      "Train Epoch: 120 [40000/60000 (67%)]\tLoss: 20.402031\n",
      "Train Epoch: 120 [50000/60000 (83%)]\tLoss: 21.443118\n",
      "====> Epoch: 120 Average loss: 18.0523\n",
      "Train Epoch: 121 [0/60000 (0%)]\tLoss: 16.345558\n",
      "Train Epoch: 121 [10000/60000 (17%)]\tLoss: 21.298591\n",
      "Train Epoch: 121 [20000/60000 (33%)]\tLoss: 17.567792\n",
      "Train Epoch: 121 [30000/60000 (50%)]\tLoss: 18.034155\n",
      "Train Epoch: 121 [40000/60000 (67%)]\tLoss: 19.369657\n",
      "Train Epoch: 121 [50000/60000 (83%)]\tLoss: 14.074441\n",
      "====> Epoch: 121 Average loss: 18.0248\n",
      "Train Epoch: 122 [0/60000 (0%)]\tLoss: 17.287628\n",
      "Train Epoch: 122 [10000/60000 (17%)]\tLoss: 17.978750\n",
      "Train Epoch: 122 [20000/60000 (33%)]\tLoss: 18.096106\n",
      "Train Epoch: 122 [30000/60000 (50%)]\tLoss: 20.834905\n",
      "Train Epoch: 122 [40000/60000 (67%)]\tLoss: 16.867941\n",
      "Train Epoch: 122 [50000/60000 (83%)]\tLoss: 17.378535\n",
      "====> Epoch: 122 Average loss: 18.1620\n",
      "Train Epoch: 123 [0/60000 (0%)]\tLoss: 22.009331\n",
      "Train Epoch: 123 [10000/60000 (17%)]\tLoss: 20.683662\n",
      "Train Epoch: 123 [20000/60000 (33%)]\tLoss: 19.184630\n",
      "Train Epoch: 123 [30000/60000 (50%)]\tLoss: 16.066205\n",
      "Train Epoch: 123 [40000/60000 (67%)]\tLoss: 19.940262\n",
      "Train Epoch: 123 [50000/60000 (83%)]\tLoss: 18.390730\n",
      "====> Epoch: 123 Average loss: 18.1445\n",
      "Train Epoch: 124 [0/60000 (0%)]\tLoss: 20.216317\n",
      "Train Epoch: 124 [10000/60000 (17%)]\tLoss: 15.838650\n",
      "Train Epoch: 124 [20000/60000 (33%)]\tLoss: 16.033087\n",
      "Train Epoch: 124 [30000/60000 (50%)]\tLoss: 21.941865\n",
      "Train Epoch: 124 [40000/60000 (67%)]\tLoss: 20.753811\n",
      "Train Epoch: 124 [50000/60000 (83%)]\tLoss: 20.611218\n",
      "Epoch   125: reducing learning rate of group 0 to 3.1250e-05.\n",
      "====> Epoch: 124 Average loss: 18.1525\n",
      "Train Epoch: 125 [0/60000 (0%)]\tLoss: 18.739495\n",
      "Train Epoch: 125 [10000/60000 (17%)]\tLoss: 20.202732\n",
      "Train Epoch: 125 [20000/60000 (33%)]\tLoss: 19.118312\n",
      "Train Epoch: 125 [30000/60000 (50%)]\tLoss: 19.757257\n",
      "Train Epoch: 125 [40000/60000 (67%)]\tLoss: 17.097101\n",
      "Train Epoch: 125 [50000/60000 (83%)]\tLoss: 18.589910\n",
      "====> Epoch: 125 Average loss: 18.1969\n",
      "Train Epoch: 126 [0/60000 (0%)]\tLoss: 14.381111\n",
      "Train Epoch: 126 [10000/60000 (17%)]\tLoss: 15.406312\n",
      "Train Epoch: 126 [20000/60000 (33%)]\tLoss: 17.222526\n",
      "Train Epoch: 126 [30000/60000 (50%)]\tLoss: 17.543490\n",
      "Train Epoch: 126 [40000/60000 (67%)]\tLoss: 18.243241\n",
      "Train Epoch: 126 [50000/60000 (83%)]\tLoss: 21.139260\n",
      "====> Epoch: 126 Average loss: 18.0236\n",
      "Train Epoch: 127 [0/60000 (0%)]\tLoss: 16.366267\n",
      "Train Epoch: 127 [10000/60000 (17%)]\tLoss: 19.467063\n",
      "Train Epoch: 127 [20000/60000 (33%)]\tLoss: 17.315697\n",
      "Train Epoch: 127 [30000/60000 (50%)]\tLoss: 15.268099\n",
      "Train Epoch: 127 [40000/60000 (67%)]\tLoss: 17.594792\n",
      "Train Epoch: 127 [50000/60000 (83%)]\tLoss: 17.564253\n",
      "====> Epoch: 127 Average loss: 18.1221\n",
      "Train Epoch: 128 [0/60000 (0%)]\tLoss: 17.766075\n",
      "Train Epoch: 128 [10000/60000 (17%)]\tLoss: 15.156765\n",
      "Train Epoch: 128 [20000/60000 (33%)]\tLoss: 17.340504\n",
      "Train Epoch: 128 [30000/60000 (50%)]\tLoss: 22.870103\n",
      "Train Epoch: 128 [40000/60000 (67%)]\tLoss: 20.732732\n",
      "Train Epoch: 128 [50000/60000 (83%)]\tLoss: 17.968599\n",
      "====> Epoch: 128 Average loss: 18.1611\n",
      "Train Epoch: 129 [0/60000 (0%)]\tLoss: 16.916466\n",
      "Train Epoch: 129 [10000/60000 (17%)]\tLoss: 19.339905\n",
      "Train Epoch: 129 [20000/60000 (33%)]\tLoss: 16.833337\n",
      "Train Epoch: 129 [30000/60000 (50%)]\tLoss: 19.150753\n",
      "Train Epoch: 129 [40000/60000 (67%)]\tLoss: 22.639587\n",
      "Train Epoch: 129 [50000/60000 (83%)]\tLoss: 18.591029\n",
      "====> Epoch: 129 Average loss: 18.1846\n",
      "Train Epoch: 130 [0/60000 (0%)]\tLoss: 18.536771\n",
      "Train Epoch: 130 [10000/60000 (17%)]\tLoss: 17.464683\n",
      "Train Epoch: 130 [20000/60000 (33%)]\tLoss: 20.241566\n",
      "Train Epoch: 130 [30000/60000 (50%)]\tLoss: 18.980763\n",
      "Train Epoch: 130 [40000/60000 (67%)]\tLoss: 16.193352\n",
      "Train Epoch: 130 [50000/60000 (83%)]\tLoss: 17.636708\n",
      "====> Epoch: 130 Average loss: 18.1967\n",
      "Train Epoch: 131 [0/60000 (0%)]\tLoss: 22.387896\n",
      "Train Epoch: 131 [10000/60000 (17%)]\tLoss: 17.340491\n",
      "Train Epoch: 131 [20000/60000 (33%)]\tLoss: 20.993970\n",
      "Train Epoch: 131 [30000/60000 (50%)]\tLoss: 16.590431\n",
      "Train Epoch: 131 [40000/60000 (67%)]\tLoss: 15.070204\n",
      "Train Epoch: 131 [50000/60000 (83%)]\tLoss: 17.881550\n",
      "====> Epoch: 131 Average loss: 18.1407\n",
      "Train Epoch: 132 [0/60000 (0%)]\tLoss: 14.965850\n",
      "Train Epoch: 132 [10000/60000 (17%)]\tLoss: 18.062800\n",
      "Train Epoch: 132 [20000/60000 (33%)]\tLoss: 17.919940\n",
      "Train Epoch: 132 [30000/60000 (50%)]\tLoss: 16.272266\n",
      "Train Epoch: 132 [40000/60000 (67%)]\tLoss: 16.891115\n",
      "Train Epoch: 132 [50000/60000 (83%)]\tLoss: 18.515455\n",
      "====> Epoch: 132 Average loss: 18.1387\n",
      "Train Epoch: 133 [0/60000 (0%)]\tLoss: 17.298269\n",
      "Train Epoch: 133 [10000/60000 (17%)]\tLoss: 16.155155\n",
      "Train Epoch: 133 [20000/60000 (33%)]\tLoss: 17.580426\n",
      "Train Epoch: 133 [30000/60000 (50%)]\tLoss: 17.627430\n",
      "Train Epoch: 133 [40000/60000 (67%)]\tLoss: 18.038221\n",
      "Train Epoch: 133 [50000/60000 (83%)]\tLoss: 18.676200\n",
      "====> Epoch: 133 Average loss: 18.2597\n",
      "Train Epoch: 134 [0/60000 (0%)]\tLoss: 15.784807\n",
      "Train Epoch: 134 [10000/60000 (17%)]\tLoss: 17.294668\n",
      "Train Epoch: 134 [20000/60000 (33%)]\tLoss: 17.734503\n",
      "Train Epoch: 134 [30000/60000 (50%)]\tLoss: 19.706165\n",
      "Train Epoch: 134 [40000/60000 (67%)]\tLoss: 16.959802\n",
      "Train Epoch: 134 [50000/60000 (83%)]\tLoss: 20.323870\n",
      "====> Epoch: 134 Average loss: 18.0779\n",
      "Train Epoch: 135 [0/60000 (0%)]\tLoss: 17.121174\n",
      "Train Epoch: 135 [10000/60000 (17%)]\tLoss: 17.847565\n",
      "Train Epoch: 135 [20000/60000 (33%)]\tLoss: 20.630269\n",
      "Train Epoch: 135 [30000/60000 (50%)]\tLoss: 15.462094\n",
      "Train Epoch: 135 [40000/60000 (67%)]\tLoss: 15.609390\n",
      "Train Epoch: 135 [50000/60000 (83%)]\tLoss: 19.558474\n",
      "Epoch   136: reducing learning rate of group 0 to 1.5625e-05.\n",
      "====> Epoch: 135 Average loss: 18.0367\n",
      "Train Epoch: 136 [0/60000 (0%)]\tLoss: 15.630613\n",
      "Train Epoch: 136 [10000/60000 (17%)]\tLoss: 16.404125\n",
      "Train Epoch: 136 [20000/60000 (33%)]\tLoss: 15.467588\n",
      "Train Epoch: 136 [30000/60000 (50%)]\tLoss: 18.713086\n",
      "Train Epoch: 136 [40000/60000 (67%)]\tLoss: 16.852816\n",
      "Train Epoch: 136 [50000/60000 (83%)]\tLoss: 16.161559\n",
      "====> Epoch: 136 Average loss: 18.0944\n",
      "Train Epoch: 137 [0/60000 (0%)]\tLoss: 19.617736\n",
      "Train Epoch: 137 [10000/60000 (17%)]\tLoss: 19.861543\n",
      "Train Epoch: 137 [20000/60000 (33%)]\tLoss: 18.205314\n",
      "Train Epoch: 137 [30000/60000 (50%)]\tLoss: 19.021051\n",
      "Train Epoch: 137 [40000/60000 (67%)]\tLoss: 20.282931\n",
      "Train Epoch: 137 [50000/60000 (83%)]\tLoss: 19.348606\n",
      "====> Epoch: 137 Average loss: 17.9833\n",
      "Train Epoch: 138 [0/60000 (0%)]\tLoss: 16.604470\n",
      "Train Epoch: 138 [10000/60000 (17%)]\tLoss: 14.357665\n",
      "Train Epoch: 138 [20000/60000 (33%)]\tLoss: 22.520698\n",
      "Train Epoch: 138 [30000/60000 (50%)]\tLoss: 17.620874\n",
      "Train Epoch: 138 [40000/60000 (67%)]\tLoss: 18.631052\n",
      "Train Epoch: 138 [50000/60000 (83%)]\tLoss: 14.159100\n",
      "====> Epoch: 138 Average loss: 18.1895\n",
      "Train Epoch: 139 [0/60000 (0%)]\tLoss: 15.767876\n",
      "Train Epoch: 139 [10000/60000 (17%)]\tLoss: 17.893070\n",
      "Train Epoch: 139 [20000/60000 (33%)]\tLoss: 15.502900\n",
      "Train Epoch: 139 [30000/60000 (50%)]\tLoss: 17.684585\n",
      "Train Epoch: 139 [40000/60000 (67%)]\tLoss: 18.122568\n",
      "Train Epoch: 139 [50000/60000 (83%)]\tLoss: 18.890804\n",
      "====> Epoch: 139 Average loss: 18.2090\n",
      "Train Epoch: 140 [0/60000 (0%)]\tLoss: 18.217594\n",
      "Train Epoch: 140 [10000/60000 (17%)]\tLoss: 17.698533\n",
      "Train Epoch: 140 [20000/60000 (33%)]\tLoss: 16.269773\n",
      "Train Epoch: 140 [30000/60000 (50%)]\tLoss: 18.380083\n",
      "Train Epoch: 140 [40000/60000 (67%)]\tLoss: 19.966511\n",
      "Train Epoch: 140 [50000/60000 (83%)]\tLoss: 21.055779\n",
      "====> Epoch: 140 Average loss: 18.1192\n",
      "Train Epoch: 141 [0/60000 (0%)]\tLoss: 17.836184\n",
      "Train Epoch: 141 [10000/60000 (17%)]\tLoss: 15.928507\n",
      "Train Epoch: 141 [20000/60000 (33%)]\tLoss: 17.556133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 141 [30000/60000 (50%)]\tLoss: 18.166931\n",
      "Train Epoch: 141 [40000/60000 (67%)]\tLoss: 15.557900\n",
      "Train Epoch: 141 [50000/60000 (83%)]\tLoss: 16.393881\n",
      "====> Epoch: 141 Average loss: 18.1108\n",
      "Train Epoch: 142 [0/60000 (0%)]\tLoss: 17.112643\n",
      "Train Epoch: 142 [10000/60000 (17%)]\tLoss: 15.880242\n",
      "Train Epoch: 142 [20000/60000 (33%)]\tLoss: 16.861460\n",
      "Train Epoch: 142 [30000/60000 (50%)]\tLoss: 14.027518\n",
      "Train Epoch: 142 [40000/60000 (67%)]\tLoss: 18.037009\n",
      "Train Epoch: 142 [50000/60000 (83%)]\tLoss: 16.507836\n",
      "====> Epoch: 142 Average loss: 18.1101\n",
      "Train Epoch: 143 [0/60000 (0%)]\tLoss: 16.202262\n",
      "Train Epoch: 143 [10000/60000 (17%)]\tLoss: 18.072213\n",
      "Train Epoch: 143 [20000/60000 (33%)]\tLoss: 20.728574\n",
      "Train Epoch: 143 [30000/60000 (50%)]\tLoss: 16.716987\n",
      "Train Epoch: 143 [40000/60000 (67%)]\tLoss: 17.794619\n",
      "Train Epoch: 143 [50000/60000 (83%)]\tLoss: 16.771727\n",
      "====> Epoch: 143 Average loss: 18.0824\n",
      "Train Epoch: 144 [0/60000 (0%)]\tLoss: 17.911010\n",
      "Train Epoch: 144 [10000/60000 (17%)]\tLoss: 17.392012\n",
      "Train Epoch: 144 [20000/60000 (33%)]\tLoss: 18.133085\n",
      "Train Epoch: 144 [30000/60000 (50%)]\tLoss: 16.701913\n",
      "Train Epoch: 144 [40000/60000 (67%)]\tLoss: 20.870059\n",
      "Train Epoch: 144 [50000/60000 (83%)]\tLoss: 18.125280\n",
      "====> Epoch: 144 Average loss: 18.0948\n",
      "Train Epoch: 145 [0/60000 (0%)]\tLoss: 20.346753\n",
      "Train Epoch: 145 [10000/60000 (17%)]\tLoss: 17.290688\n",
      "Train Epoch: 145 [20000/60000 (33%)]\tLoss: 16.682562\n",
      "Train Epoch: 145 [30000/60000 (50%)]\tLoss: 15.148060\n",
      "Train Epoch: 145 [40000/60000 (67%)]\tLoss: 15.986935\n",
      "Train Epoch: 145 [50000/60000 (83%)]\tLoss: 17.708729\n",
      "====> Epoch: 145 Average loss: 18.0508\n",
      "Train Epoch: 146 [0/60000 (0%)]\tLoss: 18.255623\n",
      "Train Epoch: 146 [10000/60000 (17%)]\tLoss: 18.892000\n",
      "Train Epoch: 146 [20000/60000 (33%)]\tLoss: 15.832856\n",
      "Train Epoch: 146 [30000/60000 (50%)]\tLoss: 19.613224\n",
      "Train Epoch: 146 [40000/60000 (67%)]\tLoss: 20.222280\n",
      "Train Epoch: 146 [50000/60000 (83%)]\tLoss: 23.080305\n",
      "Epoch   147: reducing learning rate of group 0 to 7.8125e-06.\n",
      "====> Epoch: 146 Average loss: 18.0526\n",
      "Train Epoch: 147 [0/60000 (0%)]\tLoss: 16.112036\n",
      "Train Epoch: 147 [10000/60000 (17%)]\tLoss: 21.153811\n",
      "Train Epoch: 147 [20000/60000 (33%)]\tLoss: 16.098405\n",
      "Train Epoch: 147 [30000/60000 (50%)]\tLoss: 19.847856\n",
      "Train Epoch: 147 [40000/60000 (67%)]\tLoss: 17.644409\n",
      "Train Epoch: 147 [50000/60000 (83%)]\tLoss: 16.866838\n",
      "====> Epoch: 147 Average loss: 18.0377\n",
      "Train Epoch: 148 [0/60000 (0%)]\tLoss: 17.075117\n",
      "Train Epoch: 148 [10000/60000 (17%)]\tLoss: 18.513745\n",
      "Train Epoch: 148 [20000/60000 (33%)]\tLoss: 17.399962\n",
      "Train Epoch: 148 [30000/60000 (50%)]\tLoss: 16.119113\n",
      "Train Epoch: 148 [40000/60000 (67%)]\tLoss: 17.670004\n",
      "Train Epoch: 148 [50000/60000 (83%)]\tLoss: 19.128535\n",
      "====> Epoch: 148 Average loss: 18.1493\n",
      "Train Epoch: 149 [0/60000 (0%)]\tLoss: 18.620880\n",
      "Train Epoch: 149 [10000/60000 (17%)]\tLoss: 14.883207\n",
      "Train Epoch: 149 [20000/60000 (33%)]\tLoss: 17.281437\n",
      "Train Epoch: 149 [30000/60000 (50%)]\tLoss: 16.639507\n",
      "Train Epoch: 149 [40000/60000 (67%)]\tLoss: 19.559263\n",
      "Train Epoch: 149 [50000/60000 (83%)]\tLoss: 17.990656\n",
      "====> Epoch: 149 Average loss: 17.9820\n"
     ]
    }
   ],
   "source": [
    "for i in range(150):\n",
    "    train(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
